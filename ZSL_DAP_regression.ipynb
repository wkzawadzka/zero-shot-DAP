{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lxaBB_dZG-aJ"
      },
      "outputs": [],
      "source": [
        "# import all the libraries\n",
        "import numpy as np\n",
        "import argparse\n",
        "import time\n",
        "from random import shuffle\n",
        "import random\n",
        "from sklearn import preprocessing\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.layers import Dense, Flatten, Input, Dropout\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.applications import InceptionV3\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.initializers import GlorotUniform\n",
        "from tensorflow.keras.regularizers import l1,l2\n",
        "from tensorflow.keras.optimizers import Adam"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0sl8ql8OG-aN",
        "outputId": "6f7f3ef8-ccde-4f0e-84b0-530636243c0c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/myDrive/\n"
          ]
        }
      ],
      "source": [
        "# connect to google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/myDrive/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uzB70a0FG-aN",
        "outputId": "fce459dc-0d4c-4a42-c87d-bd1c4cb2078a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/myDrive/MyDrive/ZSL\n"
          ]
        }
      ],
      "source": [
        "# go to folder with /data and /utils\n",
        "cd myDrive/MyDrive/ZSL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_FYSnsguG-aO",
        "outputId": "38d00100-1f54-4c08-d452-13a5296166e3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ]
        }
      ],
      "source": [
        "# set device as GPU\n",
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eFhYaiEQG-aO"
      },
      "source": [
        "# Zero shot learning - final project\n",
        "## DL for Spiking Neural Networks and Advanced Data Mining"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rkc_qJrVG-aQ"
      },
      "outputs": [],
      "source": [
        "from scipy import io\n",
        "att_splits=io.loadmat('./data/AWA2/binaryAtt_splits.mat')\n",
        "# retrieve all the class names\n",
        "classes_names = [a[0] for a in np.squeeze(att_splits['allclasses_names'])]\n",
        "# create helper dictionary from class id to class name\n",
        "id_to_name = {i:name for (i,name) in enumerate(classes_names)}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2HWwQo1yG-aR"
      },
      "source": [
        "### Reading data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rTRgZ0AMG-aR"
      },
      "outputs": [],
      "source": [
        "from utils import data_loader\n",
        "import importlib\n",
        "# load /utils/data_loader\n",
        "importlib.reload(data_loader)\n",
        "# load the data\n",
        "trainDataX, trainDataLabels, trainDataAttrs, testDataX, testDataLabels, testDataAttrs = data_loader.DataLoader(\"./data/CUB\", binary=False).load()\n",
        "trainDataX = (trainDataX - np.mean(trainDataX)) / np.std(trainDataX) # normalize image embeddings\n",
        "testDataX = (testDataX - np.mean(testDataX)) / np.std(testDataX) # normalize image embeddings\n",
        "\n",
        "# get the number of testing examples\n",
        "test_size = len(testDataLabels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vp9sYOAmG-aS",
        "outputId": "84842666-e667-41ee-93bb-1844d999f546"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "# check total number of classes (test & train)\n",
        "num_classes = len(np.unique(np.concatenate((trainDataLabels, testDataLabels))))\n",
        "num_classes"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Prepare input shape"
      ],
      "metadata": {
        "id": "cvD9ZyncQiOH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iQOS3gNKG-aT"
      },
      "outputs": [],
      "source": [
        "# prepare the input tensor for the model\n",
        "in_shape = trainDataX.shape[1]\n",
        "inputs = Input(shape=(in_shape,))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define useful for evaluation dictionaries"
      ],
      "metadata": {
        "id": "jh8Lq-cJQmhT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QVEX94lvG-aU"
      },
      "outputs": [],
      "source": [
        "# create class_id:attribute dictionary\n",
        "class_attr_dict = {}\n",
        "for A, B in zip(trainDataLabels, trainDataAttrs):\n",
        "    # training classes\n",
        "    class_attr_dict[A] = B\n",
        "for A, B in zip(testDataLabels, testDataAttrs):\n",
        "    # testing classes\n",
        "    class_attr_dict[A] = B\n",
        "\n",
        "# sort it from smallest to highest id\n",
        "keys = sorted(class_attr_dict)\n",
        "class_attr_dict = {i: class_attr_dict[i] for i in keys}\n",
        "class_attr_dict.keys()\n",
        "\n",
        "# create dictionary from attributes to a class id\n",
        "atrr_to_class = {v.tobytes(): k for k, v in class_attr_dict.items()}\n",
        "all_class_atrs = class_attr_dict.values()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create class_id:attribute dictionary for test classes\n",
        "test_attributes = {}\n",
        "for A, B in zip(testDataLabels, testDataAttrs):\n",
        "    test_attributes[A] = B\n",
        "test_attributes = test_attributes.values()"
      ],
      "metadata": {
        "id": "Dax65Ee0XRyh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def difference(class_attribute, prediction):\n",
        "    ''' calulate difference between predicted and actual attribute values '''\n",
        "    # assert(len(class_attribute) == len(prediction))\n",
        "    dif = 0\n",
        "    # for the each singular attribute in actual attribute representation\n",
        "    for i, att in enumerate(class_attribute):\n",
        "        # add the difference between the prediction attribute and class attribute\n",
        "        dif += abs(prediction[i] - att)\n",
        "    # return sum of differences\n",
        "    return dif\n",
        "\n",
        "def calculate_accuracy(pred, printing=False):\n",
        "  ''' get accuracy of the given model given its prediction of test dataset '''\n",
        "  correct = 0\n",
        "\n",
        "    # iterate through each test example\n",
        "  for id in range(test_size-1):\n",
        "    # get distance score\n",
        "    differences = [difference(att, pred[id]) for att in test_attributes]\n",
        "    #assert(len(differences)==10)\n",
        "\n",
        "    # take the id of the min distance\n",
        "    id_predicted = np.argmin(differences)\n",
        "    # retrive the class id of the min distance\n",
        "    class_prediction = atrr_to_class[list(test_attributes)[id_predicted].tobytes()]\n",
        "\n",
        "    # optional printing\n",
        "    if printing:\n",
        "      print(f\"predicted class: {class_prediction} real class : {testDataLabels[id]}\")\n",
        "      print(f\"predicted class: {id_to_name[class_prediction]} real class : {id_to_name[testDataLabels[id]]}\")\n",
        "      print(f\"CORRECT:::??? ->>> {class_prediction == testDataLabels[id]}\")\n",
        "\n",
        "    # if correct, add to correct variable\n",
        "    if class_prediction == testDataLabels[id]:\n",
        "      correct += 1\n",
        "\n",
        "  # return accuracy\n",
        "  return correct/test_size\n",
        "\n",
        "def get_prediction(model):\n",
        "  ''' get prediction of test dataset of a given model '''\n",
        "  # get prediction on test set\n",
        "  pred = model.predict(testDataX)\n",
        "\n",
        "  # transform to fit the attributes shape and form\n",
        "  pred = list(np.array(pred).T)[0]\n",
        "\n",
        "  # return prediction in form of [attA probability, attB probability, ...] of size 85\n",
        "  return pred"
      ],
      "metadata": {
        "id": "EN1AlBDSU2-O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prepare the models"
      ],
      "metadata": {
        "id": "mbEDLWn9MKL4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = Dropout(0.8)(inputs) # 0.8 dropout\n",
        "# linear activation for regression\n",
        "# 85 neurons as 85 attributes in AWA2\n",
        "x = Dense(85, activation='linear')(x)\n",
        "\n",
        "model1 = Model(inputs, x)\n",
        "\n",
        "with tf.device(device_name):\n",
        "  model1.compile(optimizer=Adam(learning_rate=0.001), loss='mae', metrics=['mae'])\n",
        "\n",
        "hist1 = model1.fit(trainDataX, trainDataAttrs, batch_size=64, shuffle=True, epochs=10, callbacks=[EarlyStopping(monitor='loss',min_delta=0.0001, patience=2)])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "plozRP2lbSqa",
        "outputId": "a7e576d1-b62c-4acc-eb8f-80a5287a8468"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "460/460 [==============================] - 2s 3ms/step - loss: 0.7952 - mae: 0.7952\n",
            "Epoch 2/10\n",
            "460/460 [==============================] - 1s 3ms/step - loss: 0.2550 - mae: 0.2550\n",
            "Epoch 3/10\n",
            "460/460 [==============================] - 1s 3ms/step - loss: 0.2542 - mae: 0.2542\n",
            "Epoch 4/10\n",
            "460/460 [==============================] - 2s 4ms/step - loss: 0.2537 - mae: 0.2537\n",
            "Epoch 5/10\n",
            "460/460 [==============================] - 2s 4ms/step - loss: 0.2542 - mae: 0.2542\n",
            "Epoch 6/10\n",
            "460/460 [==============================] - 1s 3ms/step - loss: 0.2533 - mae: 0.2533\n",
            "Epoch 7/10\n",
            "460/460 [==============================] - 1s 3ms/step - loss: 0.2527 - mae: 0.2527\n",
            "Epoch 8/10\n",
            "460/460 [==============================] - 1s 3ms/step - loss: 0.2539 - mae: 0.2539\n",
            "Epoch 9/10\n",
            "460/460 [==============================] - 1s 3ms/step - loss: 0.2531 - mae: 0.2531\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = Dropout(0.8)(inputs) # 0.8 dropout\n",
        "# linear activation for regression\n",
        "# 85 neurons as 85 attributes in AWA2\n",
        "x = Dense(85, activation='linear')(x)\n",
        "\n",
        "model2 = Model(inputs, x)\n",
        "\n",
        "with tf.device(device_name):\n",
        "  model2.compile(optimizer=Adam(learning_rate=0.0005), loss='mae', metrics=['mae'])\n",
        "\n",
        "hist2 = model2.fit(trainDataX, trainDataAttrs, batch_size=64, shuffle=True, epochs=10, callbacks=[EarlyStopping(monitor='loss',min_delta=0.0001, patience=2)])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I-DMeBVob9yM",
        "outputId": "9a280312-24e3-4fae-f580-93e52ee71f74"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "460/460 [==============================] - 2s 3ms/step - loss: 1.1746 - mae: 1.1746\n",
            "Epoch 2/10\n",
            "460/460 [==============================] - 1s 3ms/step - loss: 0.1697 - mae: 0.1697\n",
            "Epoch 3/10\n",
            "460/460 [==============================] - 1s 3ms/step - loss: 0.1334 - mae: 0.1334\n",
            "Epoch 4/10\n",
            "460/460 [==============================] - 1s 3ms/step - loss: 0.1328 - mae: 0.1328\n",
            "Epoch 5/10\n",
            "460/460 [==============================] - 1s 3ms/step - loss: 0.1323 - mae: 0.1323\n",
            "Epoch 6/10\n",
            "460/460 [==============================] - 1s 3ms/step - loss: 0.1323 - mae: 0.1323\n",
            "Epoch 7/10\n",
            "460/460 [==============================] - 2s 3ms/step - loss: 0.1322 - mae: 0.1322\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = Dropout(0.8)(inputs) # 0.8 dropout\n",
        "# linear activation for regression\n",
        "# 85 neurons as 85 attributes in AWA2\n",
        "x = Dense(85, activation='linear')(x)\n",
        "\n",
        "model3 = Model(inputs, x)\n",
        "\n",
        "with tf.device(device_name):\n",
        "  model3.compile(optimizer=Adam(learning_rate=0.0001), loss='mae', metrics=['mae'])\n",
        "\n",
        "hist3 = model3.fit(trainDataX, trainDataAttrs, batch_size=64, shuffle=True, epochs=10, callbacks=[EarlyStopping(monitor='loss',min_delta=0.0001, patience=2)])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E5tAs1RhcVRH",
        "outputId": "a9ac97ea-de15-4038-8c36-05895e3ce96f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "460/460 [==============================] - 2s 3ms/step - loss: 2.0331 - mae: 2.0331\n",
            "Epoch 2/10\n",
            "460/460 [==============================] - 1s 3ms/step - loss: 1.4597 - mae: 1.4597\n",
            "Epoch 3/10\n",
            "460/460 [==============================] - 1s 3ms/step - loss: 1.0041 - mae: 1.0041\n",
            "Epoch 4/10\n",
            "460/460 [==============================] - 2s 4ms/step - loss: 0.6300 - mae: 0.6300\n",
            "Epoch 5/10\n",
            "460/460 [==============================] - 2s 4ms/step - loss: 0.3238 - mae: 0.3238\n",
            "Epoch 6/10\n",
            "460/460 [==============================] - 1s 3ms/step - loss: 0.1010 - mae: 0.1010\n",
            "Epoch 7/10\n",
            "460/460 [==============================] - 1s 3ms/step - loss: 0.0457 - mae: 0.0457\n",
            "Epoch 8/10\n",
            "460/460 [==============================] - 1s 3ms/step - loss: 0.0450 - mae: 0.0450\n",
            "Epoch 9/10\n",
            "460/460 [==============================] - 1s 3ms/step - loss: 0.0447 - mae: 0.0447\n",
            "Epoch 10/10\n",
            "460/460 [==============================] - 1s 3ms/step - loss: 0.0445 - mae: 0.0445\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = Dropout(0.7)(inputs) # 0.7 dropout\n",
        "# linear activation for regression\n",
        "# 85 neurons as 85 attributes in AWA2\n",
        "x = Dense(85, activation='linear')(x)\n",
        "\n",
        "model4 = Model(inputs, x)\n",
        "\n",
        "with tf.device(device_name):\n",
        "  model4.compile(optimizer=Adam(learning_rate=0.0005), loss='mae', metrics=['mae'])\n",
        "\n",
        "hist4 = model4.fit(trainDataX, trainDataAttrs, batch_size=64, shuffle=True, epochs=10, callbacks=[EarlyStopping(monitor='loss',min_delta=0.0001, patience=2)])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-SWqSCYmcrA_",
        "outputId": "fad99326-eda2-4cd5-a9b5-505e8d43e730"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "460/460 [==============================] - 3s 3ms/step - loss: 0.9487 - mae: 0.9487\n",
            "Epoch 2/10\n",
            "460/460 [==============================] - 1s 3ms/step - loss: 0.1485 - mae: 0.1485\n",
            "Epoch 3/10\n",
            "460/460 [==============================] - 1s 3ms/step - loss: 0.1096 - mae: 0.1096\n",
            "Epoch 4/10\n",
            "460/460 [==============================] - 1s 3ms/step - loss: 0.1088 - mae: 0.1088\n",
            "Epoch 5/10\n",
            "460/460 [==============================] - 2s 5ms/step - loss: 0.1088 - mae: 0.1088\n",
            "Epoch 6/10\n",
            "460/460 [==============================] - 2s 4ms/step - loss: 0.1082 - mae: 0.1082\n",
            "Epoch 7/10\n",
            "460/460 [==============================] - 1s 3ms/step - loss: 0.1080 - mae: 0.1080\n",
            "Epoch 8/10\n",
            "460/460 [==============================] - 2s 4ms/step - loss: 0.1083 - mae: 0.1083\n",
            "Epoch 9/10\n",
            "460/460 [==============================] - 2s 4ms/step - loss: 0.1078 - mae: 0.1078\n",
            "Epoch 10/10\n",
            "460/460 [==============================] - 1s 3ms/step - loss: 0.1078 - mae: 0.1078\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = Dropout(0.4)(inputs) # 0.4 dropout\n",
        "# linear activation for regression\n",
        "# 85 neurons as 85 attributes in AWA2\n",
        "x = Dense(85, activation='linear')(x)\n",
        "\n",
        "model5 = Model(inputs, x)\n",
        "\n",
        "with tf.device(device_name):\n",
        "  model5.compile(optimizer=Adam(learning_rate=0.0005), loss='mae', metrics=['mae'])\n",
        "\n",
        "hist5 = model5.fit(trainDataX, trainDataAttrs, batch_size=64, shuffle=True, epochs=10, callbacks=[EarlyStopping(monitor='loss',min_delta=0.0001, patience=2)])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ht7MnPfPc6-0",
        "outputId": "721da582-30db-4f06-a227-57d0b76331f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "460/460 [==============================] - 2s 3ms/step - loss: 0.6456 - mae: 0.6456\n",
            "Epoch 2/10\n",
            "460/460 [==============================] - 1s 3ms/step - loss: 0.1428 - mae: 0.1428\n",
            "Epoch 3/10\n",
            "460/460 [==============================] - 1s 3ms/step - loss: 0.0771 - mae: 0.0771\n",
            "Epoch 4/10\n",
            "460/460 [==============================] - 1s 3ms/step - loss: 0.0759 - mae: 0.0759\n",
            "Epoch 5/10\n",
            "460/460 [==============================] - 1s 3ms/step - loss: 0.0751 - mae: 0.0751\n",
            "Epoch 6/10\n",
            "460/460 [==============================] - 1s 3ms/step - loss: 0.0746 - mae: 0.0746\n",
            "Epoch 7/10\n",
            "460/460 [==============================] - 1s 3ms/step - loss: 0.0742 - mae: 0.0742\n",
            "Epoch 8/10\n",
            "460/460 [==============================] - 1s 3ms/step - loss: 0.0744 - mae: 0.0744\n",
            "Epoch 9/10\n",
            "460/460 [==============================] - 2s 4ms/step - loss: 0.0743 - mae: 0.0743\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "models = [model1, model2, model3, model4, model5] # gather all the models\n",
        "# evaluate each model on the accuracy on test set\n",
        "accuracies = [calculate_accuracy(m.predict(testDataX), printing=False) for m in models]\n",
        "accuracies"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qNBL7vVnZeKl",
        "outputId": "0eabb07c-8b64-4815-cf20-fd5d9e911182"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "248/248 [==============================] - 1s 2ms/step\n",
            "248/248 [==============================] - 1s 2ms/step\n",
            "248/248 [==============================] - 0s 2ms/step\n",
            "248/248 [==============================] - 0s 2ms/step\n",
            "248/248 [==============================] - 1s 2ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.3294578541640339,\n",
              " 0.4733982054846455,\n",
              " 0.3815240743081006,\n",
              " 0.3273094907114874,\n",
              " 0.3661064071780614]"
            ]
          },
          "metadata": {},
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_model = models[np.argmax(accuracies)] # take the model with highest accuracy\n",
        "print(max(accuracies))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8i_t_DAietKh",
        "outputId": "d83b7e66-7159-4912-97a6-90f43e698760"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.4733982054846455\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# optionally save the best performing model\n",
        "final_model.save('attributes_regression')"
      ],
      "metadata": {
        "id": "yG9lgRZQfWJF"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}